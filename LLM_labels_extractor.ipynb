{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -q git+https://github.com/huggingface/accelerate.git\n","!pip install -q git+https://github.com/huggingface/transformers.git\n","!pip install -q bitsandbytes\n","!pip install -q langchain "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","device = \"cuda\"  \n","model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", load_in_4bit =True)\n","tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np  \n","import pandas as pd  \n","import json\n","import os\n","\n","jobs_posting_file_path = r'/kaggle/input/linkedin-job-postings/job_postings.csv' #https://www.kaggle.com/datasets/arshkon/linkedin-job-postings\n","df = pd.read_csv(jobs_posting_file_path)\n","\n","save_filename = \"/kaggle/working/data.json\"\n","\n","if os.path.exists(save_filename):\n","    with open(\"/kaggle/working/data.json\" , \"r\") as file:\n","        data = json.load(file)\n","else:\n","    data = []"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import json \n","from tqdm import tqdm   \n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n"," \n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=2500, chunk_overlap=250)\n"," \n","model = model.to(\"cuda\")\n","\n","for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing rows\"): \n","    job_id = row['job_id'] \n","    if any(item['job_id'] == job_id for item in data):\n","        continue \n","        \n","    fullDesc = row['description']\n","    splits = text_splitter.split_text(row['description'])   \n","    print(job_id)\n","    \n","    for index,description in enumerate(splits): \n","        \n","        messages = [\n","        {\"role\": \"user\", \"content\": f\"\"\"{description}\\n\\nFrom the job advert above, extract all information and additional context that fits under the labels stated below, \n","Then output the information in a JSON format using the labels as the key and all revelevant the information in a array of strings.\n","Inside each key want you to create a string array and extract relevant lines from the text to that key.\n","Do not create more keys under the listed labels below, for each label all extracted information should be within one single string array.\n","Labels:\n","-Required Education\n","-Required Certification\n","-Required Qualifications\n","-Required work experience\n","-Required Hard Skills\n","-Required Soft skills\n","-Benefits \n","-Company culture/values.\n","-Job duties\"\"\"\n","        }]\n","        inputs = tokenizer.apply_chat_template(\n","            messages,\n","            add_generation_prompt=True,\n","            return_tensors='pt'\n","        )\n","        tokens = model.generate(\n","            inputs.to(model.device),\n","            max_new_tokens=1024,\n","            temperature=0.2,\n","            do_sample=True \n","        )\n","        output = tokenizer.decode(tokens[0], skip_special_tokens=False).split('<|assistant|>')[1].split(\"<|endoftext|>\")[0]  \n","\n","        #print(output) \n","        data.append({\"job_id\" : job_id, \"description\": description, \"output\": output})\n","        if len(data) % 50 == 0: \n","            with open(f\"data.json\", \"w\") as file:\n","                json.dump(data, file)\n","            print(f\"Saved {len(data)} items to data_{len(data)}.json\")\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3680745,"sourceId":6893293,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
